{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment 2 - PyTorch101.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_kYM3ylzYo1Q"
      },
      "source": [
        "![PyTorch](https://devblogs.nvidia.com/wp-content/uploads/2017/04/pytorch-logo-dark.png)\n",
        "\n",
        "An open source machine learning framework that accelerates the path from research prototyping to production deployment.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WcVqSTrWY6oz"
      },
      "source": [
        "# Tensor - Pytorch's core data structure\n",
        "\n",
        "In Python we can create lists, lists of lists, lists of lists of lists and so on. In NumPy there is a `numpy.ndarray` which represents `n`- dimensional array. In math there is a special name for the generalization of vectors and matrices to a higher dimensional space - a tensor\n",
        "\n",
        "Tensor is an entity with a defined number of dimensions called an order (rank). \n",
        "\n",
        "**Scalar** can be considered as a rank-0-tensor. \n",
        "\n",
        "**Vector** can be introduced as a rank-1-tensor. \n",
        "\n",
        "**Matrices** can be considered as a rank-2-tensor.\n",
        "\n",
        "# Tensor Basics\n",
        "\n",
        "Let's import the torch module first."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-oFVL2tYYqp"
      },
      "source": [
        "import numpy as np\n",
        "import torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGxuR5IEaFJa"
      },
      "source": [
        "## Tensor Creation\n",
        "Let's view examples of matrices and tensors generation\n",
        "\n",
        "2-dimensional (rank-2) tensor of zeros:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "897JQc25aD3E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ba4312b-67e0-41b4-e0b1-47ec1f7f1fac"
      },
      "source": [
        "torch.zeros(3, 4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pujmpEBhaPRA"
      },
      "source": [
        "Random rank-3 tensor:\n",
        "_read the print below and convince yourself how this is a rank-3-tensor and learn what those 2, 3, 4 values are there for_"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBrznTNhaOL7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7308bec-682b-4977-80d9-1f785e0dda76"
      },
      "source": [
        "torch.rand(2, 3, 4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0.6429, 0.7389, 0.0713, 0.6805],\n",
              "         [0.1209, 0.0585, 0.4543, 0.6957],\n",
              "         [0.4093, 0.0015, 0.7924, 0.2399]],\n",
              "\n",
              "        [[0.3767, 0.6374, 0.5896, 0.4877],\n",
              "         [0.0376, 0.0385, 0.5995, 0.5344],\n",
              "         [0.2521, 0.6822, 0.6605, 0.4358]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kO4fIr15asdi"
      },
      "source": [
        "I am hoping you have noticed 4-elements in a row, 3 rows making one block and there are 2 blocks. \n",
        "\n",
        "Random rank-4-tensor:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KiCLvMGCaVZ3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "686b4b95-9612-4d62-bf45-cf0054c1f8fd"
      },
      "source": [
        "torch.rand(2, 2, 2, 3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[0.1619, 0.2255, 0.5693],\n",
              "          [0.2661, 0.2732, 0.8076]],\n",
              "\n",
              "         [[0.5278, 0.7231, 0.8053],\n",
              "          [0.1826, 0.7251, 0.4681]]],\n",
              "\n",
              "\n",
              "        [[[0.2005, 0.7429, 0.5236],\n",
              "          [0.2556, 0.9186, 0.9740]],\n",
              "\n",
              "         [[0.4598, 0.9097, 0.5859],\n",
              "          [0.1775, 0.6013, 0.4677]]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lF6VL68s3AMV"
      },
      "source": [
        "## Question 1:\n",
        "\n",
        "How many dimensions are there in a tensor defined as below?\n",
        ">**Ans: 4**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8IbXcI3x3Ibt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6171d6e5-ed29-45c8-f7c0-9775ef95271b"
      },
      "source": [
        "torch.rand(1, 1, 1, 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[0.6373]]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmgpqssRa9jF"
      },
      "source": [
        "---\n",
        "\n",
        "\n",
        "There are many more ways to create tensor using some restrictions on values it should contatn - for the full reference, please follow the [official docs](https://pytorch.org/docs/stable/torch.html#creation-ops). \n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# Python / NumPy / Pytorch interoperability\n",
        "\n",
        "You can create tensors from python lists as well as numpy arrays. You can also convert torch tensors to numpy arrays. So, the interoperability between torch and numpy is pretty good. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ipgpeWPfa6gE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7c1c4f3-da7e-495a-c2e2-9b52141fc06a"
      },
      "source": [
        "# Simple Python List\n",
        "python_list = [1, 2]\n",
        "\n",
        "# Create a numpy array from python list\n",
        "numpy_array = np.array(python_list)\n",
        "\n",
        "# Create a torch Tensor from python list\n",
        "tensor_from_list = torch.tensor(python_list)\n",
        "\n",
        "# Create a torch Tensor from Numpy array\n",
        "tensor_from_array = torch.tensor(numpy_array)\n",
        "\n",
        "# Another way to create a torch Tensor from Numpy array (share same storage)\n",
        "tensor_from_array_v2 = torch.from_numpy(numpy_array)\n",
        "\n",
        "# Convert torch tensor to numpy array\n",
        "array_from_tensor = tensor_from_array.numpy()\n",
        "\n",
        "print('List:   ', python_list)\n",
        "print('Array:  ', numpy_array)\n",
        "print('Tensor: ', tensor_from_list)\n",
        "print('Tensor: ', tensor_from_array)\n",
        "print('Tensor: ', tensor_from_array_v2)\n",
        "print('Array:  ', array_from_tensor)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "List:    [1, 2]\n",
            "Array:   [1 2]\n",
            "Tensor:  tensor([1, 2])\n",
            "Tensor:  tensor([1, 2])\n",
            "Tensor:  tensor([1, 2])\n",
            "Array:   [1 2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_x-86B8gqik"
      },
      "source": [
        "**Difference between** `torch.Tensor` **and** `torch.from_numpy`\n",
        "\n",
        "Pytorch aims to be an effective library for computations. What does it mean? It means that pytorch avoids memory copying if it can. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHCKDGpygn_d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "9d4a2409-7d5f-488c-d06b-a672c3141b76"
      },
      "source": [
        "numpy_array[0] = 10\n",
        "\n",
        "print('Array:  ', numpy_array)\n",
        "print('Tensor: ', tensor_from_array)\n",
        "print('Tensor: ', tensor_from_array_v2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Array:   [10  2]\n",
            "Tensor:  tensor([1, 2])\n",
            "Tensor:  tensor([10,  2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_1YTyv4wMio"
      },
      "source": [
        "**Takeaway:**\n",
        "- `torch.from_numpy` is memory efficient (i.e. it won't create copies of the original array)\n",
        "- `torch.Tensor` on the other hand allocates a new memory block (same rank as the np array) and initializes it with its values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-CKtdNRM3SMp"
      },
      "source": [
        "---\n",
        "## Question 2:\n",
        "\n",
        "Assume that we moved our complete (cats vs dogs) image dataset to numpy arrays. Then we use torch.from_numpy to convert these images to tensor. Then we apply a specific data augmentation strategy called \"CutOut\" which blocks a portion of the image directly on these tensors. What will happen to the accuracy of a model trained on this strategy compared to the one without this strategy? CutOut strategy is shown below: \n",
        "\n",
        "![CutOut](https://encrypted-tbn0.gstatic.com/images?q=tbn%3AANd9GcSnSyN835AmtQPKQbPjDHX-FmshNilbtexX95cRGQPwl56QCGDn)\n",
        "\n",
        "> **Ans: `CutOut` are an efficient way to make the model robust and learn the required features to identify the object(s) in question and not rely much on the background in which they might appear (for e.g. a plane might usually be surrounded by a sky, which might cause the network to classify anything shown with the sky as the bg as a plane). But in this case since `tensor.from_numpy` is used to convert the images in numpy and then the cutout applied directly to them the original images is being modified. So in time (i.e. over consecutive iterations the entire images might be blacked out), thus dropping the accuracy.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZq7O-aihSOA"
      },
      "source": [
        "---\n",
        "## Question 3:\n",
        "Why do you think we are observing this behavior?\n",
        "> **Ans: \n",
        "    `torch.from_numpy` is memory efficient (i.e. it won't create copies of the original array) \\\n",
        "    `torch.Tensor` on the other hand allocates a new memory block (same rank as the np array) and initializes it with its values**\n",
        "\n",
        "---\n",
        "\n",
        "We have two different ways to create tensor from its NumPy counterpart - one copies memory and another one shares the same underlying storage. It works in the opposite way:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNFOwV8EhPwQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "5c3662a8-6726-472a-b7ad-c7762136f687"
      },
      "source": [
        "array_from_tensor = tensor_from_array.numpy()\n",
        "print('Tensor: ', tensor_from_array)\n",
        "print('Array: ', array_from_tensor)\n",
        "\n",
        "tensor_from_array[0] = 11\n",
        "print('Tensor: ', tensor_from_array)\n",
        "print('Array: ', array_from_tensor)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor:  tensor([1, 2])\n",
            "Array:  [1 2]\n",
            "Tensor:  tensor([11,  2])\n",
            "Array:  [11  2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UM9ytbvKhtCw"
      },
      "source": [
        "## Data types\n",
        "\n",
        "The basic data type of all Deep Learning-related operations is float, but sometimes you may need something else. Pytorch support different number types for its tensors the same way NumPy does - by specifying the data type on tensor creation or via casting. Ths full list of supported data types can be found [here](https://pytorch.org/docs/stable/tensors.html). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bd6WkzJ4hpYi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1dde2d16-912e-405f-eba2-5e2b13984298"
      },
      "source": [
        "tensor = torch.zeros(2, 2)\n",
        "print('Tensor with default type: ', tensor)\n",
        "\n",
        "tensor = torch.zeros(2, 2, dtype=torch.float16)\n",
        "print('\\nTensor with 16-bit float: ', tensor)\n",
        "\n",
        "tensor = torch.zeros(2, 2, dtype=torch.int16)\n",
        "print('\\nTensor with integers: ', tensor)\n",
        "\n",
        "tensor = torch.zeros(2, 2, dtype=torch.bool)\n",
        "print('\\nTensor with boolean data: ', tensor)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor with default type:  tensor([[0., 0.],\n",
            "        [0., 0.]])\n",
            "\n",
            "Tensor with 16-bit float:  tensor([[0., 0.],\n",
            "        [0., 0.]], dtype=torch.float16)\n",
            "\n",
            "Tensor with integers:  tensor([[0, 0],\n",
            "        [0, 0]], dtype=torch.int16)\n",
            "\n",
            "Tensor with boolean data:  tensor([[False, False],\n",
            "        [False, False]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9F4Dkdr40TE"
      },
      "source": [
        "---\n",
        "## Question 4:\n",
        "We saw above that some times numpy and tensors share same storage and changing one changes the other. \n",
        "If we define a rank-2-tensor with ones (dtype of f16), and then convert it into a numpy data type using tensor.numpy() and store it in a variable called \"num\", and then we perform this operation `num = num * 0.5`, will the original tensor have 1.0s or 0.5s as its element values? \n",
        "\n",
        "> **Ans: Will remain unchanged as `1`; since a new memory block is created when converted to a numpy array**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QwSZj4WP0Czk",
        "outputId": "553cc8c6-5a38-418c-d7ca-b3d08a5ab6bf"
      },
      "source": [
        "num_tensor = torch.ones (2, 2, dtype=torch.float16)\n",
        "num_tensor"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1.],\n",
              "        [1., 1.]], dtype=torch.float16)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QEpvdEJ30T64",
        "outputId": "4bf95982-d7a9-4b2d-a4ff-9af271414285"
      },
      "source": [
        "num = num_tensor.numpy ()\n",
        "num"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 1.],\n",
              "       [1., 1.]], dtype=float16)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZ-dwQYW2PoE",
        "outputId": "25c152af-5704-45c7-e1d0-de6c7a8a2b7b"
      },
      "source": [
        "print (hex (id (num)), hex (id (num_tensor)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0x7eff25a7c800 0x7eff25a2b140\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L_x1KwDo0TrQ",
        "outputId": "a5279890-fcfa-4336-c3be-872c74cf3db0"
      },
      "source": [
        "num = num * 0.5\n",
        "print (hex (id (num)), hex (id (num_tensor)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0x7eff25adce40 0x7eff25a2b140\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EqCGjYqp0TW8",
        "outputId": "921b0ace-0e7f-48a6-fa13-235060aa3ef4"
      },
      "source": [
        "print (num)\n",
        "print (num_tensor)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.5 0.5]\n",
            " [0.5 0.5]]\n",
            "tensor([[1., 1.],\n",
            "        [1., 1.]], dtype=torch.float16)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OiQt8Mmm51OE"
      },
      "source": [
        "---\n",
        "## Question 5: \n",
        "If the operation `num = num*0.5` is changed to `num[:] = num*0.5` will the original tensor have 1.0s or 0.5s as its element values? \n",
        "\n",
        "> **Ans: The value of the original tensor changes to `0.5`**\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LP2uZ-p51uOk",
        "outputId": "3f546428-d781-45c2-f2a8-1da2fbcdec2d"
      },
      "source": [
        "num = num_tensor.numpy ()\n",
        "print (hex (id (num)), hex (id (num_tensor)))\n",
        "\n",
        "num [:] = num * 0.5\n",
        "print (hex (id (num)), hex (id (num_tensor)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0x7eff25a55710 0x7eff25a2b140\n",
            "0x7eff25a55710 0x7eff25a2b140\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cuPRw48c17aU",
        "outputId": "ca487ae1-56bf-4782-de3f-5b273ecd4706"
      },
      "source": [
        "print (num)\n",
        "print (num_tensor)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.5 0.5]\n",
            " [0.5 0.5]]\n",
            "tensor([[0.5000, 0.5000],\n",
            "        [0.5000, 0.5000]], dtype=torch.float16)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CEfuiaZs3EBM"
      },
      "source": [
        "num [0] = 1.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O6aPZGt03Fxs",
        "outputId": "560ef157-85cb-4d71-ac08-3d1965675b77"
      },
      "source": [
        "print (num)\n",
        "print (num_tensor)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.1 1.1]\n",
            " [0.5 0.5]]\n",
            "tensor([[1.0996, 1.0996],\n",
            "        [0.5000, 0.5000]], dtype=torch.float16)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IjY0lIKc3NWE",
        "outputId": "467fe11e-ab5d-4769-f490-09c8555d6cb4"
      },
      "source": [
        "print (hex (id (num)), hex (id (num_tensor)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0x7eff25a55710 0x7eff25a2b140\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vzh8UB8KiVmb"
      },
      "source": [
        "## Indexing\n",
        "\n",
        "Tensor provides access to its elements via the same `[]` operation as a regular python list or NumPy array. However, as you may recall from NumPy usage, the full power of math libraries is accessible only via vectorized operations, i.e. operations without explicit looping over all vector elements in python and using implicit optimized loops in C/C++/CUDA/Fortran/etc. available via special function calls. Pytorch employs the same paradigm and provides a wide range of vectorized operations. Let's take a look at some examples. \n",
        "\n",
        "Joining a list of tensors together with `torch.cat`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMaCDKPhiUAb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1cec9206-e5ba-4a6b-ca74-45b14e3286f6"
      },
      "source": [
        "a = torch.zeros(3, 2)\n",
        "b = torch.ones(3, 2)\n",
        "print(torch.cat((a, b), dim=0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.],\n",
            "        [1., 1.],\n",
            "        [1., 1.],\n",
            "        [1., 1.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bj4aeE86zdH"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "## Question 6: \n",
        "Is the transpose of concatenated a & b tensor on dimension 1, same as the contatenated tensor of a & b on dimension 0? \n",
        "\n",
        "> **Ans: No, its not the same**\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-42gafLb67Tw",
        "outputId": "e51c14f8-c13c-4ef7-ab4c-398ce5b7cf66"
      },
      "source": [
        "torch.cat ((a, b), dim=1).T"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0.],\n",
              "        [0., 0., 0.],\n",
              "        [1., 1., 1.],\n",
              "        [1., 1., 1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MSjEggHG7Bus",
        "outputId": "6bd5e84b-2799-4c2e-f19e-33edbae2bc5f"
      },
      "source": [
        "torch.cat ((a, b), dim=0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [1., 1.],\n",
              "        [1., 1.],\n",
              "        [1., 1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0TXNne69j7LP"
      },
      "source": [
        "Indexing with another tensor/array:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KiE-Fsi4jVd6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e158ddfb-4eee-4560-f8af-6455eb447350"
      },
      "source": [
        "a = torch.arange(start=0, end=10)\n",
        "indices = np.arange(0, 10) > 5\n",
        "print(a)\n",
        "print(indices)\n",
        "print(a[indices])\n",
        "\n",
        "indices = torch.arange(start=0, end=10) %5\n",
        "print(indices)\n",
        "print(a[indices])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
            "[False False False False False False  True  True  True  True]\n",
            "tensor([6, 7, 8, 9])\n",
            "tensor([0, 1, 2, 3, 4, 0, 1, 2, 3, 4])\n",
            "tensor([0, 1, 2, 3, 4, 0, 1, 2, 3, 4])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LS4dnlu47WQu"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "## Question 7:\n",
        "\n",
        "`a` is defined as `torch.arange(start=0, end=10)`. We will create `b` using the two operations as below. In both cases do we get the same value?\n",
        "\n",
        "\n",
        "1.   indices variable created by the modulo operation on arange between 0 and 10. Then a new varialble `b` is created from `a` using the last 5 elements of indices. \n",
        "2.   indices variable created by the modulo operation on arange betwenn 1 and 11. Then a new varialble `b` is created from `a` using the last 5 elements of indices. \n",
        "\n",
        "> **Ans: No, they are not the same**\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0mgoRf8X8ZOs",
        "outputId": "f95323a0-021c-446f-a40d-d09f16ab4939"
      },
      "source": [
        "a = torch.arange (start=0, end=10)\n",
        "a"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dCx-3SOT8Y40",
        "outputId": "dba5fe9e-ad96-4548-d863-48ccf1e695a9"
      },
      "source": [
        "idx_1 = torch.arange (start=0, end=10) % 5\n",
        "idx_2 = torch.arange (start=1, end=11) % 5\n",
        "\n",
        "print (idx_1 [-5:], idx_2 [-5:])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0, 1, 2, 3, 4]) tensor([1, 2, 3, 4, 0])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQ4ZCVsTk-KH"
      },
      "source": [
        "What should we do if we have, say, rank-2-tensor and want to select only some rows?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_GtRpotjkt1q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "893f7218-463d-4d6c-f4ca-2dfedb7849a1"
      },
      "source": [
        "tensor = torch.rand((5, 3))\n",
        "rows = torch.tensor([0, 2])\n",
        "print(tensor)\n",
        "tensor[rows]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.8203, 0.4171, 0.9527],\n",
            "        [0.2237, 0.2773, 0.6676],\n",
            "        [0.5434, 0.5753, 0.5061],\n",
            "        [0.0239, 0.6116, 0.2100],\n",
            "        [0.8617, 0.9906, 0.0621]])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.8203, 0.4171, 0.9527],\n",
              "        [0.5434, 0.5753, 0.5061]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zIJnr_N2_Qaf"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "## Question 8: \n",
        "\n",
        "Consider a tensor defined as `torch.rand((6, 5))`. Is the shape of the new tensor created by taking the 0th, 2nd and 4th row of the old tensor same as the shape of the a newer tensor created by taking the 0th, 2nd and 4th row of the old tensor after transposing it by operation `torch.transpose(tensor, 0, 1)` ?\n",
        "\n",
        "> **Ans: No, the transpose is not the same shape as the original, since its not a square tensor**\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dw83tCna-CPA",
        "outputId": "6d1e3c3b-01dd-4ca2-85df-e7bd05e82a2d"
      },
      "source": [
        "a = torch.rand (6, 5)\n",
        "a"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.3139, 0.0764, 0.4824, 0.2249, 0.7126],\n",
              "        [0.7487, 0.7427, 0.2390, 0.8913, 0.4314],\n",
              "        [0.0385, 0.2567, 0.3511, 0.7067, 0.8236],\n",
              "        [0.4440, 0.7488, 0.1461, 0.0392, 0.8697],\n",
              "        [0.6245, 0.3750, 0.1147, 0.9513, 0.3793],\n",
              "        [0.1599, 0.3161, 0.4800, 0.7429, 0.3671]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mOZNS4Lu-TvU",
        "outputId": "e2c87a3b-2a2b-4db8-9b36-9841efc87ab3"
      },
      "source": [
        "a [[0, 2, 4]].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 5])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nm53Wpbp-M4Q",
        "outputId": "7472d63e-30bb-4a03-df7d-b5afdaa60117"
      },
      "source": [
        "torch.transpose (a [[0, 2, 4]], 0, 1).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "naDzFMkslU0b"
      },
      "source": [
        "## Tensor Shapes\n",
        "\n",
        "Reshaping a tensor is a frequently used operation. We can change the shape of a tensor without the memory copying overhead. There are two methods for that: `reshape` and `view`. \n",
        "\n",
        "The difference is the following: \n",
        "\n",
        "\n",
        "*   view tries to return a tensor, and it shares the same memory as the original tensor. In case, if it cannot reuse the same memory due to [some reason](https://pytorch.org/docs/stable/tensors.html?highlight=view#torch.Tensor.view), it just fails. \n",
        "*   reshape always returns the tensor with the desired shape and tries to reuse the memory. If it cannot, it creates a copy\n",
        "\n",
        "Let's see with the help of an example:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HClDkqLLlMJh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a34bfde-b006-4863-fa51-4f0429cf9380"
      },
      "source": [
        "tensor = torch.rand(2, 3, 4)\n",
        "print('Pointer to data: ', tensor.data_ptr())\n",
        "print('Shape: ', tensor.shape)\n",
        "\n",
        "reshaped = tensor.reshape(24)\n",
        "print('Reshaped tensor - pointer to data', reshaped.data_ptr())\n",
        "print('Reshaped tensor shape ', reshaped.shape)\n",
        "\n",
        "view = tensor.view(3, 2, 4)\n",
        "print('Viewed tensor - pointer to data', view.data_ptr())\n",
        "print('Viewed tensor shape ', view.shape)\n",
        "\n",
        "assert tensor.data_ptr() == view.data_ptr()\n",
        "\n",
        "assert np.all(np.equal(tensor.numpy().flat, reshaped.numpy().flat))\n",
        "\n",
        "print('Original stride: ', tensor.stride())\n",
        "print('Reshaped stride: ', reshaped.stride())\n",
        "print('Viewed stride: ', view.stride())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pointer to data:  94823152966656\n",
            "Shape:  torch.Size([2, 3, 4])\n",
            "Reshaped tensor - pointer to data 94823152966656\n",
            "Reshaped tensor shape  torch.Size([24])\n",
            "Viewed tensor - pointer to data 94823152966656\n",
            "Viewed tensor shape  torch.Size([3, 2, 4])\n",
            "Original stride:  (12, 4, 1)\n",
            "Reshaped stride:  (1,)\n",
            "Viewed stride:  (8, 4, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIN5jSppm4yC"
      },
      "source": [
        "The basic rule about reshaping the tensor is definitely that you cannot change the total number of elements in it, so the product of all tensor's dimensions should always be the same. It gives us the ability to avoid specifying one dimension when reshaping the tensor - Pytorch can calculate it for us:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3D19ERFmzOl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "b49f6393-7a79-4da7-bb31-b5d8cd885e3a"
      },
      "source": [
        "print(tensor.reshape(3, 2, 4).shape)\n",
        "print(tensor.reshape(3, 2, -1).shape)\n",
        "print(tensor.reshape(3, -1, 4).shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([3, 2, 4])\n",
            "torch.Size([3, 2, 4])\n",
            "torch.Size([3, 2, 4])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ObgCQKUiETak"
      },
      "source": [
        "---\n",
        "## Question 9:\n",
        "\n",
        "Consider a tensor `a` created with [1, 2, 3] and [1, 2, 3] of size (2, 3) is reshaped with operation `.reshape(-1, 2)`. Also consider a tensor `b` created with [[2, 1]] and of size (1, 2), later operated with `view(2, -1)` operation. \n",
        "\n",
        "If we do a dot product of a and b (using `torch.mm`) and perform the sum of all the elements (using `torch.sum`) what do we get? (enter int value without any decimal point in the quiz)\n",
        "\n",
        "> **Ans: 18**\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9bDYFk5FBLBA",
        "outputId": "5c47b612-1ad9-4bd4-a7f2-4892358c99c3"
      },
      "source": [
        "a = torch.tensor ([[1, 2, 3],\n",
        "                   [1, 2, 3]]).reshape (-1, 2)\n",
        "a                   "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2],\n",
              "        [3, 1],\n",
              "        [2, 3]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fW3cg3j6BpiI",
        "outputId": "dd835630-c346-40a4-d686-2c642be1fc3e"
      },
      "source": [
        "b = torch.tensor ([[2, 1]]).view (2, -1)\n",
        "b"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2],\n",
              "        [1]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AnjNFe9qCLAU",
        "outputId": "0e8fa6b0-baa1-4f28-eee3-338c4c28d4e3"
      },
      "source": [
        "torch.sum (torch.mm (a, b))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(18)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mza7QPg3ndeV"
      },
      "source": [
        "**Alternative ways to view tensors** - `expand` or `expand_as`.\n",
        "\n",
        "\n",
        "\n",
        "*   `expand` - requires the desired shape as an input\n",
        "*   `expand_as` - uses the shape of another tensor\n",
        "\n",
        "These operations \"repeat\" tensor's values along the specified axes without actually copying the data. \n",
        "\n",
        "As the documentation says, expand:\n",
        "\n",
        "\n",
        "> returns a new view of the self tensor with singleton dimensions expanded to a larger size. Tensor can be also expanded to a larger number of dimensions, and the new ones will be appended at the front. For the new dimensions, the size cannot be set to -1. \n",
        "\n",
        "**Use case:**\n",
        "\n",
        "\n",
        "\n",
        "*   index multi-channel tensor with single-channel mask - imagine a color image with 3 channels (RGB) and binary mask for the area of interest on that image. We cannot index the image with this kind of mask directly since the dimensions are different, but we can use `expand_as` operation to create a view of the mask that has the same dimensions as the image we want to apply it to, but has not copied the data. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iz33E-V7nPQT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        },
        "outputId": "048994c8-5244-4dff-d4a6-d42282e99afc"
      },
      "source": [
        "%matplotlib inline\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# Create a black image\n",
        "image = torch.zeros(size=(3, 256, 256), dtype=torch.int)\n",
        "\n",
        "# Leave the borders and make the rest of the image Green\n",
        "image[1, 18:256 - 18, 18:256 - 18] = 255\n",
        "\n",
        "# Create a mask of the same size\n",
        "mask = torch.zeros(size=(256, 256), dtype=torch.bool)\n",
        "\n",
        "# Assuming the green region in the original image is the Region of interest, change the mask to white for that area\n",
        "mask[18:256 - 18, 18:256 - 18] = 1\n",
        "\n",
        "# Create a view of the mask with the same dimensions as the original image\n",
        "mask_expanded = mask.expand_as(image)\n",
        "print(mask_expanded.shape)\n",
        "\n",
        "mask_np = mask_expanded.numpy().transpose(1, 2, 0) * 255\n",
        "image_np = image.numpy().transpose(1, 2, 0)\n",
        "\n",
        "fig, ax = plt.subplots(1, 2)\n",
        "ax[0].imshow(image_np)\n",
        "ax[1].imshow(mask_np)\n",
        "plt.show()\n",
        "\n",
        "image[0, mask] += 128\n",
        "fig, ax = plt.subplots(1, 2)\n",
        "ax[0].imshow(image_np)\n",
        "ax[1].imshow(mask_np)\n",
        "plt.show()\n",
        "\n",
        "image[mask_expanded] += 128\n",
        "image.clamp_(0, 255)\n",
        "fig, ax = plt.subplots(1, 2)\n",
        "ax[0].imshow(image_np)\n",
        "ax[1].imshow(mask_np)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([3, 256, 256])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAC7CAYAAACend6FAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAMaklEQVR4nO3dX6hl5XnH8e+vGr1o4r9KBxmHasPcWNCJHURILBZpY7wZcyN6EYcgTC4UEmgvJulFvAmkhaQgtMIExRFSrZAE58L+sUNEvNA4jWYcterUKM4wztBaHEsgqebpxVmT7JhzPH/23mef/ZzvBxZ77Xevtdf7nvOcH2uts9faqSokSb38zqw7IEmaPMNdkhoy3CWpIcNdkhoy3CWpIcNdkhqaWrgnuTHJK0mOJtk7re1I68m61rzIND7nnuQs4FXgz4BjwLPAbVX10sQ3Jq0T61rzZFp77tcAR6vq9ar6BfAwsGtK25LWi3WtuTGtcN8KvDXy/NjQJs0z61pz4+xZbTjJHmDP8PSPZ9UPbQ5VlfXalrWt9bRUbU8r3I8D20aeXzq0jXZoH7APIIk3uNE8WLauwdrWxjCt0zLPAtuTXJ7kHOBW4MCUtiWtF+tac2Mqe+5V9X6Su4B/Ac4C7q+qF6exLWm9WNeaJ1P5KOSqO+Ghq6ZsPc+5j7K2NW1L1bZXqEpSQ4a7JDVkuEtSQ4a7JDU0s4uY1uR8YMesO6EN4zng9Kw7MRnnn38+O3ZY3Frw3HPPcfr0eMU9X+F+FfDErDuhDeM64KlZd2IyrrrqKp544olZd0MbxHXXXcdTT41X3J6WkaSGDHdJashwl6SGDHdJashwl6SGDHdJashwl6SGDHdJashwl6SGDHdJashwl6SGDHdJashwl6SGDHdJashwl6SGxrqfe5I3gPeAD4D3q2pnkouAfwQuA94Abqmq/xmvm9L6srY17yax5/6nVbWjqnYOz/cCB6tqO3BweC7NI2tbc2sap2V2AfuH+f3AzVPYhjQL1rbmxrjhXsC/Jvn3JHuGti1VdWKYfxvYMuY2pFmwtjXXxv0O1c9U1fEkvw88nuQ/Rl+sqkpSi604/MHsWew1aQOwtjXXxtpzr6rjw+Mp4AfANcDJJJcADI+nllh3X1XtHDmfKW0Y1rbm3ZrDPcnvJvnEmXngz4EjwAFg97DYbuDRcTsprSdrWx2Mc1pmC/CDJGfe5x+q6p+TPAs8kuQO4E3glvG7Ka0ra1tzb83hXlWvA1ct0v7fwA3jdEqaJWtbHXiFqiQ1ZLhLUkOGuyQ1ZLhLUkOGuyQ1ZLhLUkOGuyQ1ZLhLUkOGuyQ1ZLhLUkOGuyQ1ZLhLUkOGuyQ1ZLhLUkOGuyQ1ZLhLUkOGuyQ1ZLhLUkOGuyQ1ZLhLUkOGuyQ1tGy4J7k/yakkR0baLkryeJLXhscLh/YkuSfJ0SSHk1w9zc5L47C21dlK9twfAG78UNte4GBVbQcODs8BPgdsH6Y9wL2T6aY0FQ9gbaupZcO9qp4E3vlQ8y5g/zC/H7h5pP3BWvA0cEGSSybVWWmSrG11ttZz7luq6sQw/zawZZjfCrw1styxoe23JNmT5FCSQ2vsgzQN1rZaOHvcN6iqSlJrWG8fsA9gLetL02Zta56tdc/95JlD0uHx1NB+HNg2stylQ5s0L6xttbDWcD8A7B7mdwOPjrTfPnyy4Frg3ZFDXGkeWNtqYdnTMkkeAq4HLk5yDPg68E3gkSR3AG8CtwyLPwbcBBwFfgZ8cQp9libC2lZny4Z7Vd22xEs3LLJsAXeO2ylpPVjb6swrVCWpIcNdkhoy3CWpIcNdkhoy3CWpIcNdkhoy3CWpIcNdkhoy3CWpIcNdkhoy3CWpIcNdkhoy3CWpIcNdkhoy3CWpIcNdkhoy3CWpIcNdkhoy3CWpIcNdkhpaNtyT3J/kVJIjI213Jzme5Plhumnkta8mOZrklSSfnVbHpXFZ2+psJXvuDwA3LtL+t1W1Y5geA0hyBXAr8EfDOn+f5KxJdVaasAewttXUsuFeVU8C76zw/XYBD1fVz6vqp8BR4Jox+idNjbWtzsY5535XksPDoe2FQ9tW4K2RZY4NbdI8sbY199Ya7vcCnwR2ACeAb632DZLsSXIoyaE19kGaBmtbLawp3KvqZFV9UFW/BL7Drw9PjwPbRha9dGhb7D32VdXOqtq5lj5I02Btq4s1hXuSS0aefh4482mDA8CtSc5NcjmwHfjReF2U1o+1rS7OXm6BJA8B1wMXJzkGfB24PskOoIA3gC8BVNWLSR4BXgLeB+6sqg+m03VpPNa2Ols23KvqtkWa7/uI5b8BfGOcTknrwdpWZ16hKkkNGe6S1JDhLkkNGe6S1JDhLkkNGe6S1JDhLkkNGe6S1JDhLkkNGe6S1JDhLkkNGe6S1JDhLkkNGe6S1JDhLkkNGe6S1JDhLkkNGe6S1JDhLkkNGe6S1JDhLkkNLRvuSbYl+WGSl5K8mOTLQ/tFSR5P8trweOHQniT3JDma5HCSq6c9CGktrG11tpI99/eBv6iqK4BrgTuTXAHsBQ5W1Xbg4PAc4HPA9mHaA9w78V5Lk2Ftq61lw72qTlTVj4f594CXga3ALmD/sNh+4OZhfhfwYC14GrggySUT77k0Jmtbna3qnHuSy4BPAc8AW6rqxPDS28CWYX4r8NbIaseGNmnDsrbVzdkrXTDJx4HvAV+pqtNJfvVaVVWSWs2Gk+xh4dBWmilrWx2taM89ycdYKP7vVtX3h+aTZw5Jh8dTQ/txYNvI6pcObb+hqvZV1c6q2rnWzkvjsrbV1Uo+LRPgPuDlqvr2yEsHgN3D/G7g0ZH224dPFlwLvDtyiCttGNa2OlvJaZlPA18AXkjy/ND2NeCbwCNJ7gDeBG4ZXnsMuAk4CvwM+OJEeyxNjrWttpYN96p6CsgSL9+wyPIF3Dlmv6Sps7bVmVeoSlJDhrskNWS4S1JDhrskNWS4S1JDhrskNWS4S1JDhrskNWS4S1JDhrskNWS4S1JDhrskNWS4S1JDhrskNWS4S1JDhrskNWS4S1JDWfhymRl3YqXfLn8ecOV0+6I5chg4vbJFq2qpb1yaqpXW9nnnnceVV1rcWnD48GFOn15ZcS9V2/MV7tIabfRwl9Zqqdr2tIwkNWS4S1JDy4Z7km1JfpjkpSQvJvny0H53kuNJnh+mm0bW+WqSo0leSfLZaQ5AWitrW61V1UdOwCXA1cP8J4BXgSuAu4G/XGT5K4CfAOcClwP/CZy1zDbKyWmak7Xt1HVaqvaW3XOvqhNV9eNh/j3gZWDrR6yyC3i4qn5eVT8FjgLXLLcdab1Z2+psVefck1wGfAp4Zmi6K8nhJPcnuXBo2wq8NbLaMT76D0aaOWtb3aw43JN8HPge8JWqOg3cC3wS2AGcAL61mg0n2ZPkUJJDq1lPmjRrWx2tKNyTfIyF4v9uVX0foKpOVtUHVfVL4Dv8+vD0OLBtZPVLh7bfUFX7qmpnVe0cZwDSOKxtdbWST8sEuA94uaq+PdJ+ychinweODPMHgFuTnJvkcmA78KPJdVmaDGtbnZ29gmU+DXwBeCHJ80Pb14Dbkuxg4T+2bwBfAqiqF5M8ArwEvA/cWVUfLLON/wVeWX3359bFwH/NuhPrZCOM9Q+WaLe2J28j/L7Xy0YY61K1vWFuP3BoMx3CbqbxbqaxLmazjX8zjXejj9UrVCWpIcNdkhraKOG+b9YdWGebabybaayL2Wzj30zj3dBj3RDn3CVJk7VR9twlSRM083BPcuNwh72jSfbOuj+TMFyyfirJkZG2i5I8nuS14fHCoT1J7hnGfzjJ1bPr+ep9xJ0VW453NbrVtnU9Z+Nd7q6Q05yAs1i4s94fAuewcMe9K2bZpwmN60+Aq4EjI21/A+wd5vcCfz3M3wT8ExDgWuCZWfd/lWNd6s6KLce7ip9Lu9q2ruerrme9534NcLSqXq+qXwAPs3DnvblWVU8C73yoeRewf5jfD9w80v5gLXgauOBDV0huaLX0nRVbjncV2tW2dT1fdT3rcN9Md9nbUlUnhvm3gS3DfJufwYfurNh+vMvYLONs/3ue17qedbhvSrVwHNfqY0qL3FnxVzqOV7+t4+95nut61uG+orvsNXHyzGHa8HhqaJ/7n8Fid1ak8XhXaLOMs+3ved7retbh/iywPcnlSc4BbmXhznsdHQB2D/O7gUdH2m8f/tt+LfDuyGHfhrfUnRVpOt5V2Cy13fL33KKuZ/0fXRb+y/wqC58s+KtZ92dCY3qIhS95+D8Wzr3dAfwecBB4Dfg34KJh2QB/N4z/BWDnrPu/yrF+hoVD08PA88N0U9fxrvJn06q2rev5qmuvUJWkhmZ9WkaSNAWGuyQ1ZLhLUkOGuyQ1ZLhLUkOGuyQ1ZLhLUkOGuyQ19P8/n7qCvZYHvgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jiXBx0k3ptOI"
      },
      "source": [
        "In the example above, one can also find a couple of useful tricks:\n",
        "\n",
        "\n",
        "*   `clamp` method and function is a Pytorch's analogue of NumPy's `clip` function\n",
        "*   many operations on tensors have in-place form, that does not return modified data, but change values in the tensor. The in-place version of the operation has trailing underscore according to Pytorch's naming convension - in the exmaple above it is `clamp_`\n",
        "*   tensors have the same indexing as Numpy's arrays - one can use `:` seperated range, negative indexes and so on.\n",
        "\n",
        "---\n",
        "\n",
        "# Images and their representations\n",
        "\n",
        "Now, let's discuss images, their representations and how different Python librarties work with them. \n",
        "\n",
        "Probably, the most well-known library for image loading and simple processing is [Pillow](https://pillow.readthedocs.io/en/stable/). \n",
        "\n",
        "However, many people in deep learning area stick with OpenCV for image loading and processing with some usage of another libraries when it is justified by performance/functionality. This is because OpenCV is in general much faster than the other libraries. Here you can find a couple of benchmarks: \n",
        "\n",
        "*   https://www.kaggle.com/zfturbo/benchmark-2019-speed-of-image-reading\n",
        "*   https://github.com/albumentations-team/albumentations#benchmarking-results\n",
        "\n",
        "To sum up the benchmarks above, there are two most common image formats, PNG and JPEGs. If your data is in PNG format - use OpenCV to read it. If it is in JPEG - use libturbojpeg. For image processing, use OpenCV if possible. _We will be using PIL a lot along with these._\n",
        "\n",
        "As you will read the code from others, you may find out that some of them use Pillow/something else to read data. You should know, that color image representations in OpenCV and other libraries are different - OpenCV uses \"BGR\" channel order, while others use \"RGB\" one. \n",
        "\n",
        "To change \"BRG\" <-> \"RGB\" the only thing we need to do it to change channel order."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYv4sZMmpndu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 152
        },
        "outputId": "855ae316-3222-46f9-bbb4-b2a45af93e49"
      },
      "source": [
        "%matplotlib inline\n",
        "from matplotlib import pyplot as plt\n",
        "import cv2\n",
        "import urllib\n",
        "\n",
        "def url_to_image(url):\n",
        "\t# download the image, convert it to a NumPy array, and then read\n",
        "\t# it into OpenCV format\n",
        "\tresp = urllib.request.urlopen(url)\n",
        "\timage = np.asarray(bytearray(resp.read()), dtype=\"uint8\")\n",
        "\timage = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
        "\t# return the image\n",
        "\treturn image\n",
        "\n",
        "bgr_image = url_to_image ('https://encrypted-tbn0.gstatic.com/images?q=tbn%3AANd9GcRCA40ftnscVzfV8ft8e7vIzQXfXeZdtco8nknJrfCUW6INI40U')\n",
        "#bgr_image = cv2.imread('mars.jpg') \n",
        "# remember to add your own image in case you run this block, if you want to use the same image, \n",
        "# download it from: https://encrypted-tbn0.gstatic.com/images?q=tbn%3AANd9GcRCA40ftnscVzfV8ft8e7vIzQXfXeZdtco8nknJrfCUW6INI40U\n",
        "rgb_image = bgr_image[..., ::-1]\n",
        "fig, ax = plt.subplots(1, 2)\n",
        "ax[0].imshow(bgr_image)\n",
        "ax[1].imshow(rgb_image)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yoi4TeNBGHle"
      },
      "source": [
        "---\n",
        "\n",
        "## Question 10:\n",
        "\n",
        "Looking at the results above it can be said that the pixel values in the blue channels would be very small compared to red channel. True/False?\n",
        "\n",
        "> **Ans: True**\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3ugFd57zNwa"
      },
      "source": [
        "# Autograd\n",
        "\n",
        "Pytorch supports automatic differentiation. The module which implements this is called **AutoGrad**. It calculates the gradients and keeps track in forward and backward passes. For primitive tensors, you need to enable or disable it using the `required_grad` flag. But, for advanced tensors, it is enabled by default"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMOp4aiou6JR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fe8e9e5-cec9-408a-c9b8-fa26ff08ff3b"
      },
      "source": [
        "a = torch.rand((3, 5), requires_grad = True)\n",
        "print(a)\n",
        "result = a * 5\n",
        "print(result)\n",
        "\n",
        "# grad can be implicitly created only for scalar outputs\n",
        "# so let's calculate the sum here so that the output becomes a scalar and we can apply a backward pass\n",
        "mean_result = result.sum()\n",
        "print(mean_result)\n",
        "# calculate gradient\n",
        "mean_result.backward()\n",
        "# print gradient of a\n",
        "print(a.grad)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.2555, 0.2012, 0.4829, 0.3737, 0.0286],\n",
            "        [0.8875, 0.8545, 0.8846, 0.2994, 0.6013],\n",
            "        [0.6230, 0.5660, 0.0379, 0.6759, 0.2915]], requires_grad=True)\n",
            "tensor([[1.2777, 1.0061, 2.4147, 1.8687, 0.1428],\n",
            "        [4.4375, 4.2723, 4.4231, 1.4968, 3.0065],\n",
            "        [3.1150, 2.8301, 0.1895, 3.3797, 1.4576]], grad_fn=<MulBackward0>)\n",
            "tensor(35.3181, grad_fn=<SumBackward0>)\n",
            "tensor([[5., 5., 5., 5., 5.],\n",
            "        [5., 5., 5., 5., 5.],\n",
            "        [5., 5., 5., 5., 5.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ym0Amk2IGfLx"
      },
      "source": [
        "---\n",
        "\n",
        "## Question 11: \n",
        "\n",
        "Why the gradient of a is all 5s above?\n",
        "\n",
        "> **Ans: The fn is defined as the sum of all elementes of a*5 and since the derivative of w.r.t a is 5 it returns that**\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PDgGq2R0k7I"
      },
      "source": [
        "As we see, Pytorch automagically calculated the gradient value for us. It looks to be the correct value - we multiplied an input by 5, so the gradient of this operation equals to 5.\n",
        "\n",
        "# Disabling Autograd for tensors\n",
        "\n",
        "We don't need to compute gradients for all the variables that are involved in the pipeline. The Pytorch API provides 2 ways to disable autograd.\n",
        "\n",
        "`detach` - returns a copy of the tensor with autograd disabled. This \n",
        "\n",
        "1.   copy is built on the same memory as the original tensor, so in-place size / stride / storage changes (such as resize_ / resizeas / set / transpose) modifications are not allowed.\n",
        "2.   torch.no_grad() - It is a context manager that allows you to guard a series of operations from autograd without creating new tensors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqVG9fQb0cLW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c472d5e8-6904-45f0-a51b-a272559dd936"
      },
      "source": [
        "a = torch.rand((3, 5), requires_grad=True)\n",
        "print (a)\n",
        "\n",
        "detached_a = a.detach()\n",
        "detached_result = detached_a * 5\n",
        "print (detached_result)\n",
        "result = a * 10\n",
        "\n",
        "# we cannot do backward pass that is required for autograd using multideminsional output,\n",
        "# so let's calculate the sum here\n",
        "mean_result = result.sum()\n",
        "mean_result.backward()\n",
        "a.grad"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.0699, 0.5949, 0.0549, 0.6388, 0.6812],\n",
            "        [0.7177, 0.2876, 0.2344, 0.7021, 0.0465],\n",
            "        [0.5830, 0.1912, 0.4437, 0.2363, 0.5385]], requires_grad=True)\n",
            "tensor([[0.3493, 2.9745, 0.2745, 3.1942, 3.4059],\n",
            "        [3.5884, 1.4380, 1.1722, 3.5104, 0.2323],\n",
            "        [2.9150, 0.9562, 2.2184, 1.1814, 2.6924]])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[10., 10., 10., 10., 10.],\n",
              "        [10., 10., 10., 10., 10.],\n",
              "        [10., 10., 10., 10., 10.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqpch2Be02J7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "0a5ee8e8-81b8-46f0-c7fc-ac406657e928"
      },
      "source": [
        "a = torch.rand((3, 5), requires_grad=True)\n",
        "with torch.no_grad():\n",
        "    detached_result = a * 5\n",
        "result = a * 10\n",
        "# we cannot do backward pass that is required for autograd using multideminsional output,\n",
        "# so let's calculate the sum here\n",
        "mean_result = result.sum()\n",
        "mean_result.backward()\n",
        "a.grad"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[10., 10., 10., 10., 10.],\n",
              "        [10., 10., 10., 10., 10.],\n",
              "        [10., 10., 10., 10., 10.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjh2rYOPJUAZ"
      },
      "source": [
        "# Custom Network\n",
        "\n",
        "A fully-connected ReLU network with one hidden layer and no biases, trained to predict y from x by minimizing squared Euclidean distance.\n",
        "\n",
        "This implementation uses PyTorch tensors to manually compute the forward pass, loss, and backward pass.\n",
        "\n",
        "A PyTorch Tensor is basically the same as a numpy array: it does not know anything about deep learning or computational graphs or gradients, and is just a generic n-dimensional array to be used for arbitrary numeric computation.\n",
        "\n",
        "The biggest difference between a numpy array and a PyTorch Tensor is that a PyTorch Tensor can run on either CPU or GPU. To run operations on the GPU, just cast the Tensor to a cuda datatype."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nf5RaB104Vp"
      },
      "source": [
        "dtype = torch.float\n",
        "device = torch.device(\"cpu\")\n",
        "# device = torch.device(\"cuda:0\") # Uncomment this to run on GPU\n",
        "\n",
        "# N is batch size; D_in is input dimension;\n",
        "# H is hidden dimension; D_out is output dimension.\n",
        "N, D_in, H, D_out = 64, 1000, 100, 10\n",
        "\n",
        "# Create random input and output data\n",
        "x = torch.randn(N, D_in, device=device, dtype=dtype)\n",
        "y = torch.randn(N, D_out, device=device, dtype=dtype)\n",
        "\n",
        "# Randomly initialize weights\n",
        "w1 = torch.randn(D_in, H, device=device, dtype=dtype)\n",
        "w2 = torch.randn(H, D_out, device=device, dtype=dtype)\n",
        "\n",
        "learning_rate = 1e-6"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wBmQ0FoKyyY"
      },
      "source": [
        "w1_copy = w1.detach ().clone ()\n",
        "w2_copy = w2.detach ().clone ()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1AuauboUKhso",
        "outputId": "fbfe126a-72ea-43e5-c4b9-d9764021f62d"
      },
      "source": [
        "# Reinitialize w1 and w2\n",
        "w1 = w1_copy.detach ().clone ()\n",
        "w2 = w2_copy.detach ().clone ()\n",
        "\n",
        "for t in range(500):\n",
        "    # Forward pass: compute predicted y\n",
        "    h = x.mm(w1)\n",
        "    h_relu = h.clamp(min=0)\n",
        "    y_pred = h_relu.mm(w2)\n",
        "\n",
        "    # Compute and print loss\n",
        "    loss = (y_pred - y).pow(2).sum().item()\n",
        "    print(t, loss)\n",
        "\n",
        "    # Backprop to compute gradients of w1 and w2 with respect to loss\n",
        "    grad_y_pred = 2*(y_pred - y)\n",
        "    grad_w2 = h_relu.t().mm(grad_y_pred)\n",
        "    grad_h_relu = grad_y_pred.mm(w2.t())\n",
        "    grad_h = grad_h_relu#.clone()\n",
        "    grad_h[h < 0] = 0\n",
        "    grad_w1 = x.t().mm(grad_h)\n",
        "\n",
        "    # Update weights using gradient descent\n",
        "    w1 -= learning_rate * grad_w1\n",
        "    w2 -= learning_rate * grad_w2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 40546392.0\n",
            "1 42366028.0\n",
            "2 44626992.0\n",
            "3 38548064.0\n",
            "4 24841974.0\n",
            "5 12132409.0\n",
            "6 5398982.0\n",
            "7 2701757.5\n",
            "8 1674204.875\n",
            "9 1219170.5\n",
            "10 966369.5\n",
            "11 796200.6875\n",
            "12 668638.125\n",
            "13 567923.25\n",
            "14 486717.40625\n",
            "15 419932.65625\n",
            "16 364466.65625\n",
            "17 317975.78125\n",
            "18 278683.96875\n",
            "19 245284.0625\n",
            "20 216732.3125\n",
            "21 192203.890625\n",
            "22 171015.84375\n",
            "23 152642.515625\n",
            "24 136644.75\n",
            "25 122665.0625\n",
            "26 110403.3671875\n",
            "27 99611.40625\n",
            "28 90090.2421875\n",
            "29 81670.765625\n",
            "30 74194.4375\n",
            "31 67538.953125\n",
            "32 61600.2265625\n",
            "33 56275.30859375\n",
            "34 51492.83203125\n",
            "35 47191.30859375\n",
            "36 43312.6328125\n",
            "37 39812.01953125\n",
            "38 36649.2421875\n",
            "39 33783.703125\n",
            "40 31182.8203125\n",
            "41 28813.982421875\n",
            "42 26653.423828125\n",
            "43 24679.830078125\n",
            "44 22874.0\n",
            "45 21219.857421875\n",
            "46 19701.671875\n",
            "47 18306.927734375\n",
            "48 17024.037109375\n",
            "49 15844.060546875\n",
            "50 14756.568359375\n",
            "51 13752.423828125\n",
            "52 12825.1748046875\n",
            "53 11968.1142578125\n",
            "54 11175.662109375\n",
            "55 10441.453125\n",
            "56 9760.7587890625\n",
            "57 9129.146484375\n",
            "58 8543.01171875\n",
            "59 8000.10546875\n",
            "60 7495.0556640625\n",
            "61 7025.06640625\n",
            "62 6587.2841796875\n",
            "63 6179.2578125\n",
            "64 5799.3466796875\n",
            "65 5444.904296875\n",
            "66 5113.9326171875\n",
            "67 4806.345703125\n",
            "68 4518.89697265625\n",
            "69 4250.09814453125\n",
            "70 3998.599365234375\n",
            "71 3763.30029296875\n",
            "72 3542.879638671875\n",
            "73 3336.28857421875\n",
            "74 3142.618896484375\n",
            "75 2961.039306640625\n",
            "76 2790.66796875\n",
            "77 2630.83056640625\n",
            "78 2480.887451171875\n",
            "79 2340.01318359375\n",
            "80 2207.63720703125\n",
            "81 2083.25927734375\n",
            "82 1966.361328125\n",
            "83 1856.44921875\n",
            "84 1753.085205078125\n",
            "85 1655.8529052734375\n",
            "86 1564.3525390625\n",
            "87 1478.237060546875\n",
            "88 1397.1903076171875\n",
            "89 1320.8837890625\n",
            "90 1248.983642578125\n",
            "91 1181.2392578125\n",
            "92 1117.398193359375\n",
            "93 1057.2269287109375\n",
            "94 1000.4863891601562\n",
            "95 946.9797973632812\n",
            "96 896.489990234375\n",
            "97 848.8565673828125\n",
            "98 803.8873901367188\n",
            "99 761.4444580078125\n",
            "100 721.36572265625\n",
            "101 683.5307006835938\n",
            "102 647.787109375\n",
            "103 614.0087280273438\n",
            "104 582.1074829101562\n",
            "105 551.95166015625\n",
            "106 523.4461669921875\n",
            "107 496.498046875\n",
            "108 471.0076904296875\n",
            "109 446.9037780761719\n",
            "110 424.1116943359375\n",
            "111 402.52978515625\n",
            "112 382.11669921875\n",
            "113 362.7972717285156\n",
            "114 344.5137939453125\n",
            "115 327.205322265625\n",
            "116 310.82415771484375\n",
            "117 295.30072021484375\n",
            "118 280.5945739746094\n",
            "119 266.6632080078125\n",
            "120 253.46458435058594\n",
            "121 240.94989013671875\n",
            "122 229.08926391601562\n",
            "123 217.84439086914062\n",
            "124 207.1798858642578\n",
            "125 197.06866455078125\n",
            "126 187.47567749023438\n",
            "127 178.37283325195312\n",
            "128 169.7391357421875\n",
            "129 161.5456085205078\n",
            "130 153.75794982910156\n",
            "131 146.3667449951172\n",
            "132 139.35145568847656\n",
            "133 132.6886749267578\n",
            "134 126.3614730834961\n",
            "135 120.35133361816406\n",
            "136 114.64830017089844\n",
            "137 109.22395324707031\n",
            "138 104.07136535644531\n",
            "139 99.17305755615234\n",
            "140 94.51667785644531\n",
            "141 90.09103393554688\n",
            "142 85.88459014892578\n",
            "143 81.88288879394531\n",
            "144 78.07676696777344\n",
            "145 74.45777893066406\n",
            "146 71.01316833496094\n",
            "147 67.73886108398438\n",
            "148 64.62013244628906\n",
            "149 61.65331268310547\n",
            "150 58.830299377441406\n",
            "151 56.14224624633789\n",
            "152 53.58290481567383\n",
            "153 51.14650344848633\n",
            "154 48.825870513916016\n",
            "155 46.61480712890625\n",
            "156 44.51045227050781\n",
            "157 42.50562286376953\n",
            "158 40.595115661621094\n",
            "159 38.77598571777344\n",
            "160 37.041259765625\n",
            "161 35.389312744140625\n",
            "162 33.81365203857422\n",
            "163 32.31070327758789\n",
            "164 30.877904891967773\n",
            "165 29.511707305908203\n",
            "166 28.208656311035156\n",
            "167 26.9659481048584\n",
            "168 25.779930114746094\n",
            "169 24.64861488342285\n",
            "170 23.56890869140625\n",
            "171 22.537967681884766\n",
            "172 21.55508041381836\n",
            "173 20.61602783203125\n",
            "174 19.720474243164062\n",
            "175 18.86618995666504\n",
            "176 18.049514770507812\n",
            "177 17.26938247680664\n",
            "178 16.523900985717773\n",
            "179 15.812397003173828\n",
            "180 15.132366180419922\n",
            "181 14.482955932617188\n",
            "182 13.862346649169922\n",
            "183 13.269500732421875\n",
            "184 12.702192306518555\n",
            "185 12.160691261291504\n",
            "186 11.64313793182373\n",
            "187 11.148174285888672\n",
            "188 10.674845695495605\n",
            "189 10.222530364990234\n",
            "190 9.790336608886719\n",
            "191 9.37697982788086\n",
            "192 8.981382369995117\n",
            "193 8.60318374633789\n",
            "194 8.242066383361816\n",
            "195 7.895944118499756\n",
            "196 7.564663887023926\n",
            "197 7.248161792755127\n",
            "198 6.945390701293945\n",
            "199 6.655329704284668\n",
            "200 6.378009796142578\n",
            "201 6.112310409545898\n",
            "202 5.857998847961426\n",
            "203 5.614518165588379\n",
            "204 5.381946086883545\n",
            "205 5.158627033233643\n",
            "206 4.945343017578125\n",
            "207 4.741217136383057\n",
            "208 4.54545783996582\n",
            "209 4.358104228973389\n",
            "210 4.178781509399414\n",
            "211 4.006929874420166\n",
            "212 3.8424487113952637\n",
            "213 3.684966802597046\n",
            "214 3.534027338027954\n",
            "215 3.38940167427063\n",
            "216 3.250324010848999\n",
            "217 3.117271900177002\n",
            "218 2.9894745349884033\n",
            "219 2.867166757583618\n",
            "220 2.7499217987060547\n",
            "221 2.6378672122955322\n",
            "222 2.530254364013672\n",
            "223 2.427147150039673\n",
            "224 2.3284335136413574\n",
            "225 2.2336676120758057\n",
            "226 2.1431357860565186\n",
            "227 2.055875539779663\n",
            "228 1.9726176261901855\n",
            "229 1.8927477598190308\n",
            "230 1.8161543607711792\n",
            "231 1.7425849437713623\n",
            "232 1.672468662261963\n",
            "233 1.6050907373428345\n",
            "234 1.54035484790802\n",
            "235 1.4781965017318726\n",
            "236 1.4186997413635254\n",
            "237 1.3616732358932495\n",
            "238 1.3070037364959717\n",
            "239 1.2543699741363525\n",
            "240 1.204073190689087\n",
            "241 1.155743956565857\n",
            "242 1.109529972076416\n",
            "243 1.065024495124817\n",
            "244 1.022465705871582\n",
            "245 0.9816092848777771\n",
            "246 0.9423499703407288\n",
            "247 0.9046953320503235\n",
            "248 0.8686250448226929\n",
            "249 0.8339269161224365\n",
            "250 0.8007332682609558\n",
            "251 0.7687710523605347\n",
            "252 0.7382334470748901\n",
            "253 0.7089644074440002\n",
            "254 0.6807400584220886\n",
            "255 0.6537216901779175\n",
            "256 0.6277807354927063\n",
            "257 0.6028127670288086\n",
            "258 0.5788342952728271\n",
            "259 0.5559276938438416\n",
            "260 0.5339450240135193\n",
            "261 0.5127770900726318\n",
            "262 0.4925500154495239\n",
            "263 0.4730192720890045\n",
            "264 0.45433294773101807\n",
            "265 0.43636035919189453\n",
            "266 0.4191879332065582\n",
            "267 0.4025663137435913\n",
            "268 0.3867093324661255\n",
            "269 0.37146052718162537\n",
            "270 0.35677191615104675\n",
            "271 0.34276896715164185\n",
            "272 0.3293253481388092\n",
            "273 0.31634214520454407\n",
            "274 0.30387720465660095\n",
            "275 0.2919457256793976\n",
            "276 0.2804783880710602\n",
            "277 0.2694387137889862\n",
            "278 0.25886455178260803\n",
            "279 0.24870175123214722\n",
            "280 0.238909512758255\n",
            "281 0.2295878529548645\n",
            "282 0.22057662904262543\n",
            "283 0.21192008256912231\n",
            "284 0.2036338448524475\n",
            "285 0.19564542174339294\n",
            "286 0.18800276517868042\n",
            "287 0.180629700422287\n",
            "288 0.1735801249742508\n",
            "289 0.1667911857366562\n",
            "290 0.16031460464000702\n",
            "291 0.1540306657552719\n",
            "292 0.14801283180713654\n",
            "293 0.1422898769378662\n",
            "294 0.1367272436618805\n",
            "295 0.13139159977436066\n",
            "296 0.1262267529964447\n",
            "297 0.12133694440126419\n",
            "298 0.11657257378101349\n",
            "299 0.11204063147306442\n",
            "300 0.10766849666833878\n",
            "301 0.10349525511264801\n",
            "302 0.09947758913040161\n",
            "303 0.09559136629104614\n",
            "304 0.09186743199825287\n",
            "305 0.08829613029956818\n",
            "306 0.08488185703754425\n",
            "307 0.08156971633434296\n",
            "308 0.07840139418840408\n",
            "309 0.0753757506608963\n",
            "310 0.0724240392446518\n",
            "311 0.06961014866828918\n",
            "312 0.0669025182723999\n",
            "313 0.06431552767753601\n",
            "314 0.06184026598930359\n",
            "315 0.059439580887556076\n",
            "316 0.05715273320674896\n",
            "317 0.05492474511265755\n",
            "318 0.05280570685863495\n",
            "319 0.05076085403561592\n",
            "320 0.04880321025848389\n",
            "321 0.046916015446186066\n",
            "322 0.04512515664100647\n",
            "323 0.04336796700954437\n",
            "324 0.04169265553355217\n",
            "325 0.04010038450360298\n",
            "326 0.03855408355593681\n",
            "327 0.03704690933227539\n",
            "328 0.03562423959374428\n",
            "329 0.03425872325897217\n",
            "330 0.0329410582780838\n",
            "331 0.03167467564344406\n",
            "332 0.030464325100183487\n",
            "333 0.029292818158864975\n",
            "334 0.028169285506010056\n",
            "335 0.027089249342679977\n",
            "336 0.026056360453367233\n",
            "337 0.025060143321752548\n",
            "338 0.024098819121718407\n",
            "339 0.023170242086052895\n",
            "340 0.022292299196124077\n",
            "341 0.021441640332341194\n",
            "342 0.020611613988876343\n",
            "343 0.01982283592224121\n",
            "344 0.01907009445130825\n",
            "345 0.018351761624217033\n",
            "346 0.01765400357544422\n",
            "347 0.016990220174193382\n",
            "348 0.01635143719613552\n",
            "349 0.015723461285233498\n",
            "350 0.015126635320484638\n",
            "351 0.01455613598227501\n",
            "352 0.014008130878210068\n",
            "353 0.013482130132615566\n",
            "354 0.012976482510566711\n",
            "355 0.012490708380937576\n",
            "356 0.012015976943075657\n",
            "357 0.011566425673663616\n",
            "358 0.011128534562885761\n",
            "359 0.010711749084293842\n",
            "360 0.010317382402718067\n",
            "361 0.009938421659171581\n",
            "362 0.009571860544383526\n",
            "363 0.00921191368252039\n",
            "364 0.00886751338839531\n",
            "365 0.008538429625332355\n",
            "366 0.008218785747885704\n",
            "367 0.007919837720692158\n",
            "368 0.0076279789209365845\n",
            "369 0.0073483968153595924\n",
            "370 0.007074745371937752\n",
            "371 0.006820508278906345\n",
            "372 0.006572853308171034\n",
            "373 0.00633487431332469\n",
            "374 0.006101949140429497\n",
            "375 0.005877893418073654\n",
            "376 0.005667938385158777\n",
            "377 0.005463413428515196\n",
            "378 0.00526291923597455\n",
            "379 0.005076043773442507\n",
            "380 0.00489870086312294\n",
            "381 0.004718388896435499\n",
            "382 0.004554223269224167\n",
            "383 0.00439423555508256\n",
            "384 0.004236948676407337\n",
            "385 0.0040891035459935665\n",
            "386 0.003946692682802677\n",
            "387 0.003810396883636713\n",
            "388 0.00367803405970335\n",
            "389 0.0035503653343766928\n",
            "390 0.003424168098717928\n",
            "391 0.003308061044663191\n",
            "392 0.0031957097817212343\n",
            "393 0.003085561329498887\n",
            "394 0.002978576347231865\n",
            "395 0.0028788461349904537\n",
            "396 0.0027798365335911512\n",
            "397 0.002685762941837311\n",
            "398 0.0025969520211219788\n",
            "399 0.0025087574031203985\n",
            "400 0.00242647435516119\n",
            "401 0.0023458634968847036\n",
            "402 0.0022712545469403267\n",
            "403 0.0021955445408821106\n",
            "404 0.002125741448253393\n",
            "405 0.0020548836328089237\n",
            "406 0.001987011171877384\n",
            "407 0.0019236025400459766\n",
            "408 0.0018633336294442415\n",
            "409 0.001800833735615015\n",
            "410 0.0017459405353292823\n",
            "411 0.0016928428085520864\n",
            "412 0.0016392713878303766\n",
            "413 0.00158673245459795\n",
            "414 0.0015364042483270168\n",
            "415 0.0014894094783812761\n",
            "416 0.0014444044791162014\n",
            "417 0.0013971314765512943\n",
            "418 0.001357606379315257\n",
            "419 0.0013158395886421204\n",
            "420 0.001277375966310501\n",
            "421 0.0012397827813401818\n",
            "422 0.0012017465196549892\n",
            "423 0.001167247537523508\n",
            "424 0.0011315662413835526\n",
            "425 0.0010986370034515858\n",
            "426 0.0010662417626008391\n",
            "427 0.0010355038102716208\n",
            "428 0.0010052378056570888\n",
            "429 0.0009775081416592002\n",
            "430 0.000947941152844578\n",
            "431 0.0009229106944985688\n",
            "432 0.0008971040952019393\n",
            "433 0.0008718657772988081\n",
            "434 0.0008481821278110147\n",
            "435 0.000825385854113847\n",
            "436 0.000801165821030736\n",
            "437 0.0007815333665348589\n",
            "438 0.0007592262700200081\n",
            "439 0.0007368849474005401\n",
            "440 0.0007177458028309047\n",
            "441 0.0006989442626945674\n",
            "442 0.000680325785651803\n",
            "443 0.0006623762892559171\n",
            "444 0.0006440451252274215\n",
            "445 0.0006273345788940787\n",
            "446 0.0006117182783782482\n",
            "447 0.0005962742725387216\n",
            "448 0.0005810523871332407\n",
            "449 0.000566717004403472\n",
            "450 0.0005523842410184443\n",
            "451 0.0005377736524678767\n",
            "452 0.0005250497488304973\n",
            "453 0.0005131802172400057\n",
            "454 0.000500157882925123\n",
            "455 0.00048771966248750687\n",
            "456 0.00047569090384058654\n",
            "457 0.0004633113567251712\n",
            "458 0.0004538893699645996\n",
            "459 0.00044225435703992844\n",
            "460 0.00043309092870913446\n",
            "461 0.0004232476931065321\n",
            "462 0.000413331959862262\n",
            "463 0.00040416105184704065\n",
            "464 0.00039477436803281307\n",
            "465 0.000385317369364202\n",
            "466 0.0003769265895243734\n",
            "467 0.0003686387208290398\n",
            "468 0.0003598982293624431\n",
            "469 0.00035251767258159816\n",
            "470 0.0003446863265708089\n",
            "471 0.00033696068567223847\n",
            "472 0.00032978062517941\n",
            "473 0.0003225340333301574\n",
            "474 0.00031612347811460495\n",
            "475 0.0003086476062890142\n",
            "476 0.0003027172351721674\n",
            "477 0.0002968623593915254\n",
            "478 0.00029014653409831226\n",
            "479 0.00028364951140247285\n",
            "480 0.0002787416451610625\n",
            "481 0.00027283182134851813\n",
            "482 0.0002674002025742084\n",
            "483 0.0002618888975121081\n",
            "484 0.0002563988382462412\n",
            "485 0.00025127659318968654\n",
            "486 0.00024602317716926336\n",
            "487 0.00024215428857132792\n",
            "488 0.00023719333694316447\n",
            "489 0.0002323984808754176\n",
            "490 0.00022838125005364418\n",
            "491 0.00022402431932277977\n",
            "492 0.0002199486189056188\n",
            "493 0.00021634275617543608\n",
            "494 0.0002121087454725057\n",
            "495 0.00020771179697476327\n",
            "496 0.00020400616631377488\n",
            "497 0.00020011313608847558\n",
            "498 0.00019611866446211934\n",
            "499 0.00019214529311284423\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ycwxAPHZLNST"
      },
      "source": [
        "---\n",
        "## Question 12\n",
        "\n",
        "In the code above, why do we have 2 in '2.0*(y_pred - y)`?\n",
        "\n",
        "> Ans: Loss function is defined as $ \\Sigma (y_{pred} - y)^2 $, so its derivative would have as mentioned in the question\n",
        "\n",
        "---\n",
        "## Question 13\n",
        "In the code above, what does `grad_h[h < 0] = 0` signify?\n",
        "\n",
        "> **Ans: Since ReLu was used as the activations the gradient whose value of h is less than 0 was clipped, so its derivatives are also 0**\n",
        "\n",
        "---\n",
        "## Question 14\n",
        "In the code above, how many \"epochs\" have we trained the model for? \n",
        "\n",
        "> **Ans: 500**\n",
        "\n",
        "---\n",
        "## Question 15\n",
        "In the code above, if we take the trained model, and run it on fresh  inputs, the trained model will be able to predict fresh output with high accuracy. \n",
        "\n",
        "> **Ans: No, the loss is still high and also it was trained on random data, so which wouldn't not have any significance with the output y (x & y are random)**\n",
        "\n",
        "---\n",
        "## Question 16\n",
        "In the code above, if we dont use clone in `grad_h = grad_h_relu.clone()` the model will still train without any issues. \n",
        "\n",
        "> **Ans: Yes, it runs without any issue and also returns the same results**\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PnJ49I07JJI6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}